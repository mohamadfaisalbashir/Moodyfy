# -*- coding: utf-8 -*-
"""Moodyfy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1shX-_mQF-BK0oIxpn1iw5YDcX1i9_fO-

# **Moodyfy: Sistem Rekomendasi Musik Berbasis Mood & Pola Audio**

**Deskripsi Projek:**
Projek ini bertujuan untuk membangun sistem rekomendasi musik melalui pendekatan berbasis Machine Learning. Sistem ini mengidentifikasi mood dari lagu menggunakan klasifikasi, mengelompokkan lagu berdasarkan karakteristik audio, dan memberikan rekomendasi lagu yang serupa.

**Metodologi:**
1.  **Klasifikasi Mood (Supervised):** Menggunakan *Random Forest* untuk memprediksi mood (Happy, Sad, Calm, Energetic) pada dataset lagu yang belum berlabel.
2.  **Klastering Pola (Unsupervised):** Menggunakan *K-Means Clustering* untuk mengelompokkan lagu berdasarkan fitur audio.
3.  **Sistem Rekomendasi:** Menggunakan *K-Nearest Neighbors (KNN)* untuk mencari kemiripan lagu (*similarity search*).

**Dataset:**
- `data_moods.csv`: Data latih dengan label mood.
- `data.csv`: Data lagu Spotify umum (unlabeled).

# **1. Import Library**
Mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import random
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer
from sklearn.decomposition import PCA
from typing import List
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings("ignore")

"""## **2. Memuat Dataset**

Pada tahap ini berfokus pada pemuatan dataset ke dalam notebook lalu mengecek informasi dataset sebelum nantinya dilakukan pembersihan.

**Fokus Analisis:**
   - Memuat dataset ke dalam notebook dan menampilkan 5 baris pertama.
"""

# Load data dengan label mood dan menampilkan 5 baris pertama.
df_labeled = pd.read_csv('data_moods.csv')
df_labeled.head()

# Load data dengan lagu tanpa label dan menampilkan 5 baris pertama.
df_unlabeled = pd.read_csv('data.csv')
df_unlabeled.head()

"""## **3. Exploratory Data Analysis (EDA): Visualisasi Fitur Audio**

Tahap ini bertujuan untuk memahami karakteristik statistik dari fitur audio dan bagaimana fitur-fitur tersebut berinteraksi satu sama lain.

**Fokus Analisis:**
* **Analisis Korelasi (Heatmap):** Mengidentifikasi hubungan linear antar fitur (misalnya, hubungan positif antara *Energy* dan *Loudness*).
"""

# Tabel heatmap korelasi antar fitur
plt.figure(figsize=(12, 8))
sns.heatmap(df_labeled.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Korelasi antar fitur dengan data berlabel")
plt.show()

# Tabel heatmap korelasi antar fitur
plt.figure(figsize=(12, 8))
sns.heatmap(df_unlabeled.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Korelasi antar fitur dengan data tanpa label")
plt.show()

"""## **4. Pembersihan dan Pra Pemrosesan Data**

Tahap ini bertujuan untuk pembersihan data, karena Machine Learning belajar dari data apa adanya, sehingga data yang kotor, tidak lengkap, atau tidak konsisten akan menyebabkan model menangkap pola yang salah dan menghasilkan prediksi yang tidak akurat.

**Fokus Analisis:**
* **Menghapus data dulpikat:** Menghapus lagu yang muncul berulang untuk mencegah bias pada distribusi fitur.
* **Pembersihan Nilai Kosong:** Menghapus atau menangani data yang tidak lengkap guna menjaga konsistensi vektor fitur audio.
* **Feature Selection:** Memilih fitur numeri pada audio agar menghasilkan hasil yang relevan.
* **Standarisasi (StandardScaler):** Menyamakan skala fitur ke dalam distribusi yang seragam agar tidak ada perbedaan rentang nilai yang sangat berbeda.
"""

# Menghapus duplikat data dengan fitur name dan artis
df_labeled = df_labeled.drop_duplicates(subset=['name', 'artist'], keep='first')
df_unlabeled = df_unlabeled.drop_duplicates(subset=['name', 'artists'], keep='first')

# Menghapus missing values (data kosong)
df_labeled = df_labeled.dropna()
df_unlabeled = df_unlabeled.dropna()

# Reset index agar index nya urut kembali (0, 1, 2...)
df_labeled = df_labeled.reset_index(drop=True)
df_unlabeled = df_unlabeled.reset_index(drop=True)

# Fitur numerik untuk masalah pengelompokan
features = ['danceability', 'acousticness', 'energy', 'instrumentalness',
           'liveness', 'valence', 'loudness', 'speechiness', 'tempo']

# Memisahkan fitur dan label untuk membagi data menjadi data latih 75% dan data uji 25%
X = df_labeled[features]
y = df_labeled['mood']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Standarisasi data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## **6. Model Training & Evaluation (Random Forest)**

Tahap ini mencakup pembangunan model untuk pelabelan otomatis.

**Fokus Analisis:**
* **Klasifikasi Mood:** Melatih model *Random Forest* untuk memprediksi mood pada dataset utama berdasarkan karakteristik audio yang telah dipelajari.
* **Performance Metrics:** Mengevaluasi akurasi klasifikasi melalui *Classification Report*.
"""

# Melatih model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)

# Menghitung nilai precision, recall, F1 score, dan support
y_pred = rf_model.predict(X_test_scaled)
print("Classification Report (75:25) :")
print(classification_report(y_test, y_pred))

# Melakukan ekstraksi fitur dan normalisasi data
X_unlabeled = df_unlabeled[features]
X_unlabeled_scaled = scaler.transform(X_unlabeled)

# Melakukan prediksi mood menggunakan model Random Forest
predictions = rf_model.predict(X_unlabeled_scaled)

# Menyimpan hasil prediksi ke dalam kolom baru 'mood'
df_unlabeled['mood'] = predictions

# Menampilkan 5 baris pertama untuk verifikasi hasil
df_unlabeled.head()

# Mengukur pentingnya fitur pada model
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': rf_model.feature_importances_
})
print("\nFeature Importance:")
print(feature_importance.sort_values('importance', ascending=False))

# Menyimpan hasil data training
df_unlabeled.to_csv('music_with_mood.csv', index=False)

"""## **7. Feature Engineering & Scaling**

Tahap ini bertujuan untuk mentransformasi fitur audio mentah menjadi format numerik yang terstandarisasi agar model dapat memberikan bobot pada setiap parameter.

**Fokus Analisis:**
* **Feature Selection:** Mengisolasi fitur-fitur audio spesifik yang memiliki pengaruh signifikan terhadap persepsi mood musik.
* **Standarisasi (StandardScaler):** Menyamakan skala fitur ke dalam distribusi yang seragam karena algoritma berbasis jarak (KNN & K-Means) sangat sensitif terhadap perbedaan rentang nilai.
"""

# Load data hasil training dan menampilkan 5 baris pertama.
df = pd.read_csv("music_with_mood.csv")
df = df.reset_index(drop=True)
df.head()

# Pilih fitur numerik untuk pengelompokan
numerical_features = [
    "valence", "danceability", "energy", "tempo",
    "acousticness", "liveness", "speechiness", "instrumentalness"
]

# Standarisasi data
scaler = StandardScaler()
df_scaled = pd.DataFrame(
    scaler.fit_transform(df[numerical_features]),
    columns=numerical_features
)

"""## **8. Membangun model K-Means Clustering**

Tahap ini mencakup pengelompokan pola lagu secara intrinsik.

**Fokus Analisis:**
* **Clustering:** Menggunakan K-Means untuk menemukan segmen lagu yang memiliki kemiripan suara secara otomatis tanpa bergantung pada label.
* **Performance:** Mengevaluasi kualitas cluster melalui Silhouette Score.
* **Visualisasi:** Melakukan visualisasi Elbow Method untuk menentukan jumlah cluster terbaik.
"""

# Melakukan visualisasi Elbow Method menggunakan KElbowVisualizer()
model = KMeans(random_state=42)
elbow = KElbowVisualizer(model, k=(2, 12), metric='distortion', timings=False)
elbow.fit(X_unlabeled_scaled)

elbow.show()

# K-Means Clustering
optimal_k = 5
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
df["Cluster"] = kmeans.fit_predict(df_scaled)

# Visualisasi kluster menggunakan PCA (Analisis Komponen Utama)
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df_scaled)

# Plot kluster
plt.figure(figsize=(10, 8))
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=df["Cluster"], cmap="viridis")
plt.title("K-Means Clusters")
plt.show()

# Silhouette score
score = silhouette_score(X_unlabeled_scaled, kmeans.labels_, metric='euclidean')
print(f"Silhouette Score untuk K-Means: {score:.4f}")

# Menyimpan hasil data clustering
df.to_csv("clustered_df.csv")

"""**9. Sistem rekomendasi menggunakan K-Nearest Neighbors (KNN)**

Tahap akhir ini mengintegrasikan seluruh komponen menjadi satu sistem pemberi rekomendasi lagu menggunakan prinsip pencarian tetangga terdekat.

**Fokus Analisis:**
* **KNN:** Menghitung jarak Euclidean antar lagu dalam ruang fitur untuk menemukan kemiripan maksimal.
* **Recommendation Logic:** Mengambil input lagu atau mood pengguna dan menyajikan daftar rekomendasi lagu yang paling mirip dengan input.
"""

# Inisialisasi model KNN (mencari 6 tetangga terdekat)
model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=6)
model_knn.fit(X_unlabeled_scaled)

# Judul Lagu
judul = input("Masukkan judul lagu: ")

# Cari rekomendasi lagu
try:
    filter_lagu = df_unlabeled[df_unlabeled['name'].str.lower() == judul.lower()]
    idx = filter_lagu.index[0]

    # Cari 5 lagu terdekat menggunakan KNN
    distances, indices = model_knn.kneighbors(X_unlabeled_scaled[idx].reshape(1, -1))

    print(f"\nLagu ditemukan: {df_unlabeled.iloc[idx]['name']} - {df_unlabeled.iloc[idx]['artists']}")
    print("Berikut 5 rekomendasi lagu:")

    # Menampilkan 5 hasil rekomendasi (index 1 sampai 5)
    for i in range(1, 6):
        res_idx = indices.flatten()[i]
        print(f"- {df_unlabeled.iloc[res_idx]['name']} oleh {df_unlabeled.iloc[res_idx]['artists']}")

# error handling jika input salah atau tidak ada
except IndexError:
    print(f"Maaf lagu '{judul}' tidak ditemukan. sepertinya lagu belum tersedia di database dan pastikan judul sudah tepat")

# Input mood dari user
mood_input = input("Gimana mood saat ini (Happy, Sad, Calm, Energetic): ").title()

# Filter lagu berdasarkan mood hasil prediksi Random Forest
mood_songs = df_unlabeled[df_unlabeled['mood'] == mood_input]

# Error handling jika input salah
if mood_songs.empty:
  print(f"Mood '{mood_input}' tidak ditemukan dalam dataset.")

# Pilih satu lagu secara acak dari mood untuk dijadikan acuan dalam pencarian KNN
chosen_song_sample = mood_songs.sample(n=1)
chosen_idx = chosen_song_sample.index[0]

print(f"\nBerdasarkan mood {mood_input}, kami gunakan lagu: '{df_unlabeled.loc[chosen_idx, 'name']}' sebagai dasar rekomendasi")

# Inisialisasi & Fit KNN
knn = NearestNeighbors(n_neighbors=21, metric='cosine')
knn.fit(X_unlabeled_scaled)

# Mencari tetangga terdekat dari lagu yang terpilih
distances, indices = knn.kneighbors(X_unlabeled_scaled[chosen_idx].reshape(1, -1))

# Mengambil index tetangga (abaikan index pertama karena itu lagu itu sendiri)
neighbors_indices = indices[0][1:]

# Mengambil 5 sampel acak dari tetangga tersebut
recommended_indices = random.sample(list(neighbors_indices), 5)
rec_songs = df_unlabeled.loc[recommended_indices, ['name', 'artists', 'mood']]

# Menampilkan rekomendasi lagu
print("\nBerikut 5 rekomendasi lagu:")
for _, row in rec_songs.iterrows():
  print(f"- {row['name']} oleh {row['artists']} (Mood: {row['mood']})")

# Menghitung nilai Precision@K
match_count = rec_songs[rec_songs['mood'] == mood_input].shape[0]
accuracy_by_mood = (match_count / 5)
print(f"Precision@K: {accuracy_by_mood}")